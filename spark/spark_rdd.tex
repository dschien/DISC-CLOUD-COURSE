%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame {\frametitle{What is an RDD}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
	\item {\bf RDD are partitioned, locality aware, distributed collections}
	\begin{itemize}
		\item RDD are \emph{immutable}
	\end{itemize}

	\vspace{20pt}

	\item {\bf RDD are data structures that:}
	\begin{itemize}
		\item Either point to a direct data source (e.g. HDFS)
		\item Apply some transformations to its parent RDD(s) to generate new data elements
	\end{itemize}

	\vspace{20pt}

	\item {\bf Computations on RDDs}
	\begin{itemize}
	 	\item Represented by \emph{lazily evaluated} lineage \emph{DAGs} composed by chained RDDs
	 \end{itemize} 
\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame {\frametitle{RDD Abstraction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
	\item {\bf Overall objective}
	\begin{itemize}
		\item Support a wide array of operators (more than just \texttt{Map} and \texttt{Reduce})
		\item Allow arbitrary composition of such operators
	\end{itemize}

	\vspace{20pt}

	\item {\bf Simplify scheduling}
	\begin{itemize}
		\item Avoid to modify the scheduler for each operator
	\end{itemize}

	\vspace{20pt}

	\item[$\to$] The question is: \emph{How to capture dependencies in a general way?}
\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame {\frametitle{RDD Interfaces}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
	\item {\bf Set of partitions (``splits'')}
	\begin{itemize}
		\item Much like in Hadoop MapReduce, each RDD is associated to (input) partitions
	\end{itemize}

	\item {\bf List of dependencies on parent RDDs}
	\begin{itemize}
		\item This is completely new w.r.t. Hadoop MapReduce
	\end{itemize}

	\item {\bf Function to compute a partition given parents}
	\begin{itemize}
		\item This is actually the ``user-defined code'' we referred to when discussing about the \texttt{Mapper} and \texttt{Reducer} classes in Hadoop
	\end{itemize}

	\item {\bf Optional preferred locations}
	\begin{itemize}
		\item This is to enforce data locality
	\end{itemize}

	\item {\bf Optional partitioning info (Partitioner)}
	\begin{itemize}
		\item This really helps in some ``advanced'' scenarios in which you want to pay attention to the behavior of the shuffle mechanism
	\end{itemize}
\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame {\frametitle{Hadoop RDD}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
	\item {\color{mauve} partitions} = one per HDFS block

	\vspace{10pt}

	\item {\color{mauve} dependencies} = none

	\vspace{10pt}

	\item {\color{mauve} compute(partition)} = read corresponding block

	\vspace{10pt}

	\item {\color{mauve} preferredLocations(part)} = HDFS block location

	\vspace{10pt}

	\item {\color{mauve} partitioner} = none

\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame {\frametitle{Filtered RDD}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
	\item {\color{mauve} partitions} = same as parent RDD

	\vspace{10pt}

	\item {\color{mauve} dependencies} = \emph{one-to-one} on parent

	\vspace{10pt}

	\item {\color{mauve} compute(partition)} = compute parent and filter it

	\vspace{10pt}

	\item {\color{mauve} preferredLocations(part)} = none (\emph{ask parent})

	\vspace{10pt}

	\item {\color{mauve} partitioner} = none

\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame {\frametitle{Joined RDD}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
	\item {\color{mauve} partitions} = one per reduce task

	\vspace{10pt}

	\item {\color{mauve} dependencies} = \emph{shuffle} on \emph{each} parent

	\vspace{10pt}

	\item {\color{mauve} compute(partition)} = read and join shuffled data

	\vspace{10pt}

	\item {\color{mauve} preferredLocations(part)} = none 

	\vspace{10pt}

	\item {\color{mauve} partitioner} = HashPartitioner(numTask)\footnote{Spark knows this data is hashed.}

\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame {\frametitle{Dependency Types (1)}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{columns}[t, onlytextwidth]
	\begin{column}[T]{.4\textwidth}
		\begin{center}
			{ \tiny \bf Narrow dependencies}
		\end{center}
		\begin{figure}[h]
			\includegraphics[scale=0.3]{./Figures/narrow_deps}
		\end{figure}
	\end{column}

	\begin{column}[T]{.4\textwidth}
		\begin{center}
			{ \tiny \bf Wide dependencies}
		\end{center}
		\begin{figure}[h]
			\includegraphics[scale=0.3]{./Figures/wide_deps}
		\end{figure}
	\end{column}
\end{columns}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame {\frametitle{Dependency Types (2)}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
	\item {\bf Narrow dependencies}
	\begin{itemize}
		\item Each partition of the parent RDD is used by at most one partition of the child RDD
		\item Task can be executed locally and we don't have to shuffle. (Eg: \texttt{map}, \texttt{flatMap}, \texttt{filter}, \texttt{sample})
	\end{itemize}

	\vspace{20pt}

	\item {\bf Wide Dependencies}
	\begin{itemize}
		\item Multiple child partitions may depend on one partition of the parent RDD 
		\item This means we have to shuffle data \textbf{unless the parents are hash-partitioned} (Eg: \texttt{sortByKey}, \texttt{reduceByKey}, \texttt{groupByKey}, \texttt{cogroupByKey}, \texttt{join}, \texttt{cartesian})
	\end{itemize}
\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame {\frametitle{Dependency Types: Optimizations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
	\item {\bf Benefits of Lazy evaluation:} The DAG Scheduler optimizes \emph{Stages} and \emph{Tasks} before submitting them to the Task Scheduler
	\begin{itemize}
		\item Examples:
		\begin{itemize}
			\item \textbf{Piplining} narrow dependencies within a Stage
			\item \textbf{Join plan selection} based on partitioning
			\item \textbf{Cache reuse}
		\end{itemize}
	\end{itemize}
\end{itemize}

\begin{figure}[h]
	\includegraphics[scale=0.5]{./Figures/deps_optimization}
\end{figure}

}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame {\frametitle{Operations on RDDs: Transformations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
	\item {\bf Transformations}
	\begin{itemize}
		\item Set of operations on a RDD that define how they should be transformed
		\item As in relational algebra, the application of a transformation to an RDD yields a new RDD (because RDDs are \emph{immutable})
		\item Transformations are lazily evaluated, which allow for optimizations to take place before execution
	\end{itemize}

	\vspace{10pt}

	\item {\bf Examples} (not exhaustive)
	\begin{itemize}
		\item \texttt{map(func)}, \texttt{flatMap(func)}, \texttt{filter(func)}
		\item \texttt{grouByKey()}
		\item \texttt{reduceByKey(func)}, \texttt{mapValues(func)}, \texttt{distinct()}, \texttt{sortByKey(func)}
		\item \texttt{join(other)}, \texttt{union(other)}
		\item \texttt{sample()}
	\end{itemize}

\end{itemize}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame {\frametitle{Operations on RDDs: Actions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
	\item {\bf Actions}
	\begin{itemize}
		\item Apply transformation chains on RDDs, eventually performing some additional operations (e.g., counting)
		\item Some actions only store data to an external data source (e.g. HDFS), others fetch data from the RDD (and its transformation chain) upon which the action is applied, and convey it to the driver
	\end{itemize}

	\vspace{20pt}

	\item {\bf Examples} (not exhaustive)
	\begin{itemize}
		\item \texttt{reduce(func)}
		\item \texttt{collect()}, \texttt{first()}, \texttt{take()}, \texttt{foreach(func)}
		\item \texttt{count()}, \texttt{countByKey()}
		\item \texttt{saveAsTextFile()}
	\end{itemize}

\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame {\frametitle{Operations on RDDs: Final Notes}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}

	\item {\bf Look at return types!}
	\begin{itemize}
		\item Return type: RDD $\to$ transformation
		\item Return type: built-in scala/java types such as \texttt{int}, \texttt{long}, \texttt{List<Object>}, \texttt{Array<Object>} $\to$ action
	\end{itemize}

	\vspace{10pt}

	\item {\bf Caching is a transformation}
	\begin{itemize}
		\item Hints to keep RDD in memory after its first evaluation
	\end{itemize}

	\vspace{10pt}

	\item {\bf Transformations depend on RDD ``flavor''}
	\begin{itemize}
		\item \texttt{PairRDD}
		\item \texttt{SchemaRDD}
	\end{itemize}

\end{itemize}
}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \frame {\frametitle{RDD Code Snippet}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 	\begin{figure}[h]
% 	\center
% 		\includegraphics[scale=0.5]{./Figures/rdd_snippet}
% 	\end{figure}


% 	\begin{itemize}
% 		\item {\bf SparkContext}
% 		\begin{itemize}
% 			\item This is the main entity responsible for setting up a job
% 			\item Contains SparkConfig, Scheduler, entry point of running jobs (runJobs)
% 		\end{itemize}

% 		\vspace{15pt}

% 		\item {\bf Dependencies}
% 		\begin{itemize}
% 			\item Input RDD(s)
% 		\end{itemize}
% 	\end{itemize}
% }

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \frame {\frametitle{RDD.map operation Snippet}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 	\begin{itemize}
% 		\item {\bf Map: RDD[T] $\to$ RDD[U]}
% 	\end{itemize}

% 	\begin{figure}[h]
% 	\center
% 		\includegraphics[scale=0.5]{./Figures/rddmap_snippet}
% 	\end{figure}

% 	\begin{itemize}
% 		\item {\bf MappedRDD}
% 		\begin{itemize}
% 			\item For each element in a partition, apply function $f$
% 		\end{itemize}
% 	\end{itemize}

% 	\begin{figure}[h]
% 	\center
% 		\includegraphics[scale=0.5]{./Figures/mappedrdd_snippet}
% 	\end{figure}

% }

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \frame {\frametitle{RDD Iterator Code Snipped}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{itemize}
% 	\item {\bf Method to go through an RDD and apply function $f$}
% 	\begin{itemize}
% 		\item First, check local cache
% 		\item If not found, compute the RDD
% 	\end{itemize}
% \end{itemize}

% 	\begin{figure}[h]
% 	\center
% 		\includegraphics[scale=0.45]{./Figures/iterator_snippet}
% 	\end{figure}


% \begin{itemize}
% 	\item {\bf Storage Levels}
% 	\begin{itemize}
% 		\item Disk
% 		\item Memory
% 		\item Off Heap (e.g. external memory stores like Tachyon)
% 		\item De-serialized
% 	\end{itemize}
% \end{itemize}

% }

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \frame {\frametitle{Making RDD from local collections}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 	\begin{itemize}
% 		\item {\bf Convert a local (on the driver) Seq[T] into RDD[T]}
% 	\end{itemize}

% 	\begin{figure}[h]
% 	\center
% 		\includegraphics[scale=0.45]{./Figures/parallelize_snippet}
% 	\end{figure}


% }

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \frame {\frametitle{Hadoop RDD Code Snippet}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{itemize}
% 	\item {\bf Reading HDFS data as <key, value> records}
% \end{itemize}

% \begin{figure}[h]
% 	\center
% 		\includegraphics[scale=0.45]{./Figures/HadoopRDD_snippet}
% \end{figure}
% }

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  \begin{colorblock}{blue}{lightblue}{ }
%   \begin{center}
%     \Large \textbf{\texttt{Understanding RDD Operations}}
%   \end{center}
%   \end{colorblock}
% \end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \frame {\frametitle{Common Transformations}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{columns}[t, onlytextwidth]
% 	\begin{column}[T]{.3\textwidth}
% 		\begin{center}
% 			\texttt{map(f: T => U)}	
% 		\end{center}
% 	\end{column}

% 	\begin{column}[T]{.5\textwidth}
		
% 			Returns a \texttt{MappedRDD[U]} by applying $f$ to each element
		
% 	\end{column}
% \end{columns}

% \begin{figure}[h]
% 	\includegraphics[scale=0.6]{./Figures/transformation_map}
% \end{figure}

% }

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \frame {\frametitle{Common Transformations}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{columns}[t, onlytextwidth]
% 	\begin{column}[T]{.4\textwidth}
% 		\begin{center}
% 			\texttt{flatMap(f: T => TraversableOnce[U])}	
% 		\end{center}
% 	\end{column}

% 	\begin{column}[T]{.4\textwidth}
		
% 			Returns a \texttt{FlatMappedRDD[U]} by first applying $f$ to each element, then flattening the results
		
% 	\end{column}
% \end{columns}

% \begin{figure}[h]
% 	\includegraphics[scale=0.6]{./Figures/transformation_flatmap}
% \end{figure}

% }


